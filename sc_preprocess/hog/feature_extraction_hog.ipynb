{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Extraction - HOG\n",
        "## Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng HOG t·ª´ ·∫£nh grayscale ƒë√£ preprocessing\n",
        "\n",
        "C√°c b∆∞·ªõc th·ª±c hi·ªán:\n",
        "1. **Load ·∫£nh ƒë√£ preprocessing**: ƒê·ªçc t·ª´ preprocessed_hog/\n",
        "2. **Tr√≠ch xu·∫•t HOG features**: T√≠nh HOG descriptor\n",
        "3. **L∆∞u features**: L∆∞u feature vectors v√†o .npz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Import th∆∞ vi·ªán\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from skimage.feature import hog\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train images: (10968, 128, 128)\n",
            "Test images: (2743, 128, 128)\n",
            "S·ªë l·ªõp: 23\n"
          ]
        }
      ],
      "source": [
        "# 2. Load ·∫£nh grayscale ƒë√£ preprocessing\n",
        "\n",
        "# Load train data\n",
        "train_data = np.load('preprocessed_hog/train_data.npz')\n",
        "X_train_img = train_data['X']\n",
        "y_train = train_data['y']\n",
        "\n",
        "# Load test data\n",
        "test_data = np.load('preprocessed_hog/test_data.npz')\n",
        "X_test_img = test_data['X']\n",
        "y_test = test_data['y']\n",
        "\n",
        "# Load class mapping\n",
        "with open('preprocessed_hog/class_mapping.json', 'r') as f:\n",
        "    class_mapping = json.load(f)\n",
        "class_mapping = {int(k): v for k, v in class_mapping.items()}\n",
        "\n",
        "print(f\"Train images: {X_train_img.shape}\")\n",
        "print(f\"Test images: {X_test_img.shape}\")\n",
        "print(f\"S·ªë l·ªõp: {len(class_mapping)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HOG parameters:\n",
            "   - Orientations: 9\n",
            "   - Pixels per cell: (8, 8)\n",
            "   - Cells per block: (2, 2)\n"
          ]
        }
      ],
      "source": [
        "# 3. ƒê·ªãnh nghƒ©a h√†m tr√≠ch xu·∫•t HOG features\n",
        "# Tham s·ªë HOG\n",
        "HOG_ORIENTATIONS = 9\n",
        "HOG_PIXELS_PER_CELL = (8, 8)\n",
        "HOG_CELLS_PER_BLOCK = (2, 2)\n",
        "\n",
        "# Tr√≠ch xu·∫•t HOG features t·ª´ ·∫£nh grayscale ƒë√£ normalize\n",
        "def extract_hog_features(img_gray):\n",
        "    \n",
        "    # Chuy·ªÉn v·ªÅ 0-255 ƒë·ªÉ HOG ho·∫°t ƒë·ªông t·ªët h∆°n\n",
        "    img_255 = (img_gray * 255).astype('uint8')\n",
        "    \n",
        "    # Tr√≠ch xu·∫•t HOG features\n",
        "    features = hog(\n",
        "        img_255,\n",
        "        orientations=HOG_ORIENTATIONS,\n",
        "        pixels_per_cell=HOG_PIXELS_PER_CELL,\n",
        "        cells_per_block=HOG_CELLS_PER_BLOCK,\n",
        "        visualize=False,\n",
        "        feature_vector=True\n",
        "    )\n",
        "    \n",
        "    return features\n",
        "\n",
        "print(f\"HOG parameters:\")\n",
        "print(f\"   - Orientations: {HOG_ORIENTATIONS}\")\n",
        "print(f\"   - Pixels per cell: {HOG_PIXELS_PER_CELL}\")\n",
        "print(f\"   - Cells per block: {HOG_CELLS_PER_BLOCK}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10968/10968 [00:33<00:00, 323.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train features shape: (10968, 8100)\n",
            "Feature vector length: 8100\n"
          ]
        }
      ],
      "source": [
        "# 4. Tr√≠ch xu·∫•t HOG features t·ª´ train data\n",
        "\n",
        "X_train_features = []\n",
        "for img in tqdm(X_train_img, desc=\"Train\"):\n",
        "    features = extract_hog_features(img)\n",
        "    X_train_features.append(features)\n",
        "\n",
        "X_train_features = np.array(X_train_features)\n",
        "\n",
        "print(f\"Train features shape: {X_train_features.shape}\")\n",
        "print(f\"Feature vector length: {X_train_features.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2743/2743 [00:08<00:00, 310.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test features shape: (2743, 8100)\n",
            "Feature vector length: 8100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 5. Tr√≠ch xu·∫•t HOG features t·ª´ test data\n",
        "\n",
        "X_test_features = []\n",
        "for img in tqdm(X_test_img, desc=\"Test\"):\n",
        "    features = extract_hog_features(img)\n",
        "    X_test_features.append(features)\n",
        "\n",
        "X_test_features = np.array(X_test_features)\n",
        "\n",
        "print(f\"Test features shape: {X_test_features.shape}\")\n",
        "print(f\"Feature vector length: {X_test_features.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ƒê√£ l∆∞u train_features.npz, test_features.npz v√† metadata\n"
          ]
        }
      ],
      "source": [
        "# 6. L∆∞u features\n",
        "\n",
        "output_dir = 'features_hog'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# L∆∞u train features\n",
        "np.savez_compressed(\n",
        "    f'{output_dir}/train_features.npz',\n",
        "    X=X_train_features,\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "# L∆∞u test features\n",
        "np.savez_compressed(\n",
        "    f'{output_dir}/test_features.npz',\n",
        "    X=X_test_features,\n",
        "    y=y_test\n",
        ")\n",
        "\n",
        "# L∆∞u class mapping\n",
        "with open(f'{output_dir}/class_mapping.json', 'w') as f:\n",
        "    json.dump(class_mapping, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "# L∆∞u feature info\n",
        "feature_info = {\n",
        "    'method': 'HOG (Histogram of Oriented Gradients)',\n",
        "    'hog_orientations': HOG_ORIENTATIONS,\n",
        "    'hog_pixels_per_cell': HOG_PIXELS_PER_CELL,\n",
        "    'hog_cells_per_block': HOG_CELLS_PER_BLOCK,\n",
        "    'feature_vector_length': int(X_train_features.shape[1]),\n",
        "    'train_samples': len(X_train_features),\n",
        "    'test_samples': len(X_test_features),\n",
        "    'num_classes': len(class_mapping)\n",
        "}\n",
        "\n",
        "with open(f'{output_dir}/feature_info.json', 'w') as f:\n",
        "    json.dump(feature_info, f, indent=2)\n",
        "\n",
        "print(\"ƒê√£ l∆∞u train_features.npz, test_features.npz v√† metadata\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Ho√†n th√†nh!\n",
            "\n",
            "üì¶ Th∆∞ m·ª•c 'features_hog':\n",
            "   ‚îú‚îÄ‚îÄ train_features.npz: (10968, 8100)\n",
            "   ‚îú‚îÄ‚îÄ test_features.npz: (2743, 8100)\n",
            "   ‚îú‚îÄ‚îÄ class_mapping.json\n",
            "   ‚îî‚îÄ‚îÄ feature_info.json\n",
            "\n",
            "üìù Features: HOG (8100 dimensions)\n",
            "\n",
            "‚û°Ô∏è Ti·∫øp theo: Scale ‚Üí PCA ‚Üí Train v·ªõi SVC + SMOTE\n"
          ]
        }
      ],
      "source": [
        "# 7. T·ªïng k·∫øt\n",
        "print(f\"\\n‚úÖ Ho√†n th√†nh!\")\n",
        "print(f\"\\nüì¶ Th∆∞ m·ª•c '{output_dir}':\")\n",
        "print(f\"   ‚îú‚îÄ‚îÄ train_features.npz: {X_train_features.shape}\")\n",
        "print(f\"   ‚îú‚îÄ‚îÄ test_features.npz: {X_test_features.shape}\")\n",
        "print(f\"   ‚îú‚îÄ‚îÄ class_mapping.json\")\n",
        "print(f\"   ‚îî‚îÄ‚îÄ feature_info.json\")\n",
        "print(f\"\\nüìù Features: HOG ({X_train_features.shape[1]} dimensions)\")\n",
        "print(f\"\\n‚û°Ô∏è Ti·∫øp theo: Scale ‚Üí PCA ‚Üí Train v·ªõi SVC + SMOTE\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py_CV",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
