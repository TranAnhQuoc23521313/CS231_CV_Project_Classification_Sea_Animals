{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing cho HOG\n",
        "## Chuẩn bị ảnh grayscale cho HOG feature extraction\n",
        "\n",
        "Các bước thực hiện:\n",
        "1. **Load dữ liệu**: Đọc file từ thư mục split_data\n",
        "2. **Preprocessing**: Resize + chuyển sang grayscale\n",
        "3. **Lưu ảnh**: Lưu ảnh grayscale đã preprocess\n",
        "\n",
        "**Lưu ý**: Bước này chỉ preprocessing, chưa trích xuất HOG features!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Import thư viện\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Số lớp: 23\n",
            "Classes: ['Clams', 'Corals', 'Crabs', 'Dolphin', 'Eel', 'Fish', 'Jelly Fish', 'Lobster', 'Nudibranchs', 'Octopus', 'Otter', 'Penguin', 'Puffers', 'Sea Rays', 'Sea Urchins', 'Seahorse', 'Seal', 'Sharks', 'Shrimp', 'Squid', 'Starfish', 'Turtle_Tortoise', 'Whale']\n"
          ]
        }
      ],
      "source": [
        "# 2. Load class mapping\n",
        "with open('split_data/class_mapping.json', 'r') as f:\n",
        "    class_mapping = json.load(f)\n",
        "\n",
        "# Chuyển key từ string sang int\n",
        "class_mapping = {int(k): v for k, v in class_mapping.items()}\n",
        "\n",
        "print(f\"Số lớp: {len(class_mapping)}\")\n",
        "print(f\"Classes: {list(class_mapping.values())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Image size: (128, 128)\n",
            "✓ Method: Grayscale preprocessing for HOG\n"
          ]
        }
      ],
      "source": [
        "# 3. Định nghĩa hàm preprocessing\n",
        "IMAGE_SIZE = (128, 128)\n",
        "# Preprocessing ảnh cho HOG: resize + grayscale\n",
        "def preprocess_for_hog(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        return None\n",
        "    \n",
        "    # Resize\n",
        "    img = cv2.resize(img, IMAGE_SIZE)\n",
        "    \n",
        "    # Chuyển sang grayscale\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # Normalize 0-1\n",
        "    img_gray = img_gray.astype('float32') / 255.0\n",
        "    \n",
        "    return img_gray\n",
        "\n",
        "print(f\"✓ Image size: {IMAGE_SIZE}\")\n",
        "print(f\"✓ Method: Grayscale preprocessing for HOG\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Clams: 100%|██████████| 398/398 [00:01<00:00, 221.51it/s]\n",
            "Train Corals: 100%|██████████| 400/400 [00:02<00:00, 193.79it/s]\n",
            "Train Crabs: 100%|██████████| 399/399 [00:02<00:00, 193.01it/s]\n",
            "Train Dolphin: 100%|██████████| 625/625 [00:02<00:00, 249.91it/s]\n",
            "Train Eel: 100%|██████████| 398/398 [00:01<00:00, 224.52it/s]\n",
            "Train Fish: 100%|██████████| 395/395 [00:01<00:00, 315.76it/s]\n",
            "Train Jelly Fish: 100%|██████████| 676/676 [00:01<00:00, 434.54it/s]\n",
            "Train Lobster: 100%|██████████| 399/399 [00:00<00:00, 1162.50it/s]\n",
            "Train Nudibranchs: 100%|██████████| 400/400 [00:00<00:00, 1359.52it/s]\n",
            "Train Octopus: 100%|██████████| 450/450 [00:00<00:00, 1160.52it/s]\n",
            "Train Otter: 100%|██████████| 400/400 [00:00<00:00, 1450.87it/s]\n",
            "Train Penguin: 100%|██████████| 386/386 [00:00<00:00, 1413.80it/s]\n",
            "Train Puffers: 100%|██████████| 425/425 [00:00<00:00, 1351.43it/s]\n",
            "Train Sea Rays: 100%|██████████| 414/414 [00:00<00:00, 1513.26it/s]\n",
            "Train Sea Urchins: 100%|██████████| 463/463 [00:00<00:00, 1268.74it/s]\n",
            "Train Seahorse: 100%|██████████| 382/382 [00:00<00:00, 1405.88it/s]\n",
            "Train Seal: 100%|██████████| 331/331 [00:00<00:00, 1452.08it/s]\n",
            "Train Sharks: 100%|██████████| 472/472 [00:00<00:00, 1508.08it/s]\n",
            "Train Shrimp: 100%|██████████| 390/390 [00:00<00:00, 1373.06it/s]\n",
            "Train Squid: 100%|██████████| 386/386 [00:00<00:00, 1460.52it/s]\n",
            "Train Starfish: 100%|██████████| 399/399 [00:00<00:00, 963.04it/s] \n",
            "Train Turtle_Tortoise: 100%|██████████| 1522/1522 [00:01<00:00, 1284.03it/s]\n",
            "Train Whale: 100%|██████████| 458/458 [00:00<00:00, 1628.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (10968, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "# 4. Load và preprocessing train data\n",
        "\n",
        "train_dir = 'split_data/train'\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for class_idx, class_name in class_mapping.items():\n",
        "    class_path = os.path.join(train_dir, class_name)\n",
        "    if not os.path.exists(class_path):\n",
        "        continue\n",
        "    \n",
        "    images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
        "    \n",
        "    for img_file in tqdm(images, desc=f\"Train {class_name}\"):\n",
        "        img_path = os.path.join(class_path, img_file)\n",
        "        img = preprocess_for_hog(img_path)\n",
        "        \n",
        "        if img is not None:\n",
        "            X_train.append(img)\n",
        "            y_train.append(class_idx)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "print(f\"Train shape: {X_train.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test Clams: 100%|██████████| 99/99 [00:00<00:00, 1328.62it/s]\n",
            "Test Corals: 100%|██████████| 100/100 [00:00<00:00, 1282.03it/s]\n",
            "Test Crabs: 100%|██████████| 100/100 [00:00<00:00, 1175.74it/s]\n",
            "Test Dolphin: 100%|██████████| 157/157 [00:00<00:00, 1169.49it/s]\n",
            "Test Eel: 100%|██████████| 99/99 [00:00<00:00, 1207.32it/s]\n",
            "Test Fish: 100%|██████████| 99/99 [00:00<00:00, 1441.38it/s]\n",
            "Test Jelly Fish: 100%|██████████| 169/169 [00:00<00:00, 1438.05it/s]\n",
            "Test Lobster: 100%|██████████| 100/100 [00:00<00:00, 1298.28it/s]\n",
            "Test Nudibranchs: 100%|██████████| 100/100 [00:00<00:00, 1424.67it/s]\n",
            "Test Octopus: 100%|██████████| 112/112 [00:00<00:00, 1331.90it/s]\n",
            "Test Otter: 100%|██████████| 100/100 [00:00<00:00, 1470.53it/s]\n",
            "Test Penguin: 100%|██████████| 96/96 [00:00<00:00, 1349.40it/s]\n",
            "Test Puffers: 100%|██████████| 106/106 [00:00<00:00, 1340.52it/s]\n",
            "Test Sea Rays: 100%|██████████| 103/103 [00:00<00:00, 1509.24it/s]\n",
            "Test Sea Urchins: 100%|██████████| 116/116 [00:00<00:00, 1281.34it/s]\n",
            "Test Seahorse: 100%|██████████| 96/96 [00:00<00:00, 1411.83it/s]\n",
            "Test Seal: 100%|██████████| 83/83 [00:00<00:00, 1371.37it/s]\n",
            "Test Sharks: 100%|██████████| 118/118 [00:00<00:00, 1610.24it/s]\n",
            "Test Shrimp: 100%|██████████| 98/98 [00:00<00:00, 1441.10it/s]\n",
            "Test Squid: 100%|██████████| 97/97 [00:00<00:00, 1576.58it/s]\n",
            "Test Starfish: 100%|██████████| 100/100 [00:00<00:00, 1360.33it/s]\n",
            "Test Turtle_Tortoise: 100%|██████████| 381/381 [00:00<00:00, 1464.53it/s]\n",
            "Test Whale: 100%|██████████| 114/114 [00:00<00:00, 1624.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test shape: (2743, 128, 128)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 5. Load và preprocessing test data\n",
        "\n",
        "test_dir = 'split_data/test'\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for class_idx, class_name in class_mapping.items():\n",
        "    class_path = os.path.join(test_dir, class_name)\n",
        "    if not os.path.exists(class_path):\n",
        "        continue\n",
        "    \n",
        "    images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
        "    \n",
        "    for img_file in tqdm(images, desc=f\"Test {class_name}\"):\n",
        "        img_path = os.path.join(class_path, img_file)\n",
        "        img = preprocess_for_hog(img_path)\n",
        "        \n",
        "        if img is not None:\n",
        "            X_test.append(img)\n",
        "            y_test.append(class_idx)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(f\"Test shape: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã lưu train_data.npz, test_data.npz và metadata\n"
          ]
        }
      ],
      "source": [
        "# 6. Lưu ảnh đã preprocessing\n",
        "\n",
        "output_dir = 'preprocessed_hog'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Lưu train data\n",
        "np.savez_compressed(\n",
        "    f'{output_dir}/train_data.npz',\n",
        "    X=X_train,\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "# Lưu test data\n",
        "np.savez_compressed(\n",
        "    f'{output_dir}/test_data.npz',\n",
        "    X=X_test,\n",
        "    y=y_test\n",
        ")\n",
        "\n",
        "# Lưu class mapping\n",
        "with open(f'{output_dir}/class_mapping.json', 'w') as f:\n",
        "    json.dump(class_mapping, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "# Lưu preprocessing info\n",
        "preprocessing_info = {\n",
        "    'method': 'Grayscale Preprocessing',\n",
        "    'image_size': IMAGE_SIZE,\n",
        "    'color_space': 'Grayscale',\n",
        "    'normalization': '0-1',\n",
        "    'train_samples': len(X_train),\n",
        "    'test_samples': len(X_test),\n",
        "    'num_classes': len(class_mapping)\n",
        "}\n",
        "\n",
        "with open(f'{output_dir}/preprocessing_info.json', 'w') as f:\n",
        "    json.dump(preprocessing_info, f, indent=2)\n",
        "\n",
        "print(\"Đã lưu train_data.npz, test_data.npz và metadata\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py_CV",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
